{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "savegan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "As3teMKNDPrp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7435b299-4bac-4d6b-deb4-2a862f407bcb"
      },
      "source": [
        "'''\n",
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "'''\n",
        "\n",
        "#import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Install TensorFlow\\ntry:\\n  # %tensorflow_version only exists in Colab.\\n  %tensorflow_version 2.x\\nexcept Exception:\\n  pass\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr6HeT9auSIi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "b6fd2be9-2da4-40cd-ed61-da2ca0b2cd1e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ccURu7QvNLx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "e73c25df-6f4f-4417-8a48-bd98088c92b4"
      },
      "source": [
        "# Import relevant libraries and fix the random seeds of both tensorflow and numpy!\n",
        "\n",
        "import tensorflow as tf; #tf.set_random_seed(0); \n",
        "import numpy as np; np.random.seed(0);\n",
        "import matplotlib.pyplot as plt; import pylab; import os; from os import listdir; \n",
        "import warnings; warnings.filterwarnings(\"ignore\"); import random;\n",
        "\n",
        "# Some Global Variables\n",
        "batch_sz = 1; img_height = 256; img_width = 256; img_channels = 3; pool_size = 50;\n",
        "picasso_dir = 'gdrive/My Drive/NST Dataset/Sample pic/'; scene_dir = 'gdrive/My Drive/NST Dataset/Sample scene/';\n",
        "\n",
        "# File names of the corresponding dataset (Monet painitings and Cezzane paintings)\n",
        "pic_file_name = [picasso_dir + s for s in os.listdir(picasso_dir)]; \n",
        "scene_file_name = [scene_dir + s for s in os.listdir(scene_dir)];\n",
        "\n",
        "# Create a global array to store the images generated by the Generator while training\n",
        "fake_a_arr = fake_b_arr = np.zeros((pool_size, batch_sz, img_height, img_width, img_channels));\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ2b9Rw6u63X"
      },
      "source": [
        "def summary(var, name):\n",
        "    \n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    var:  Variable whose summary will get plotted on tensorboard\n",
        "    name: Variable's name that will be assigned to it\n",
        "    \n",
        "    \"\"\"  \n",
        "    \n",
        "    with tf.variable_scope(name):\n",
        "#       Mean and Standard Deviation of the variable \n",
        "        mu = tf.reduce_mean(var); sigma = tf.sqrt(tf.reduce_mean(tf.square(var - mu)));\n",
        "#       Histogram plot of the variable\n",
        "        tf.summary.histogram('Histogram', var); tf.summary.scalar(\"Mean\", mu); tf.summary.scalar(\"Std_dev\", sigma);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuM-mbRtuaaP"
      },
      "source": [
        "def get_tensor_slices(tensor): \n",
        "    \n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  Tensor:  Simple or Nested structures of tensors \n",
        "    \n",
        "  Returns:\n",
        "  Dataset: Dataset format of the above tensor \n",
        "  \"\"\"\n",
        "  return tf.data.Dataset.from_tensor_slices(tensor)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep3qUwRxxgpT"
      },
      "source": [
        "# Get the iterators corresponding to both the dataset\n",
        "def get_iterators(sess):\n",
        "    \n",
        "  #  Shuffle and repeat the datset, Apply the mapping transformation, Batch and prefetch (one or n) of them\n",
        "\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  sess:           Session of tensorflow\n",
        "  \n",
        "  Returns:\n",
        "  handle:         A scalar tf.Tensor of type tf.string that evaluates to a handle \n",
        "  next_element:   A nested structure of tf.Tensors representing the next element\n",
        "  train_iterator: Iterator corresponding to the training dataset\n",
        "  train_handle:   String-valued tf.Tensor that represents the train iterator\n",
        "  \"\"\"\n",
        "\n",
        "  pic_dataset = get_tensor_slices(tf.constant(pic_file_name)); scene_dataset = get_tensor_slices(tf.constant(scene_file_name));\n",
        "\n",
        "  pic_dataset = pic_dataset.shuffle(500).repeat(); \n",
        "  pic_dataset = pic_dataset.map(lambda x: tf.subtract(tf.div(tf.image.resize_images(tf.image.decode_jpeg(tf.read_file(x)), \\\n",
        "                        [img_height, img_width]), 127.5), 1))\n",
        "\n",
        "  scene_dataset = scene_dataset.shuffle(500).repeat();\n",
        "  scene_dataset = scene_dataset.map(lambda x: tf.subtract(tf.div(tf.image.resize_images(tf.image.decode_jpeg(tf.read_file(x)), \\\n",
        "                        [img_height, img_width]), 127.5), 1))\n",
        "\n",
        "  pic_dataset = (pic_dataset.batch(batch_sz)).prefetch(1); scene_dataset = (scene_dataset.batch(batch_sz)).prefetch(1);\n",
        "  \n",
        "  handle = tf.placeholder(tf.string, shape = []);\n",
        "  iterator = tf.data.Iterator.from_string_handle(handle, output_types = pic_dataset.output_types, \n",
        "              output_shapes = pic_dataset.output_shapes)\n",
        "  next_element = iterator.get_next();\n",
        "  \n",
        "  pic_iterator = pic_dataset.make_initializable_iterator(); pic_handle = sess.run(pic_iterator.string_handle());\n",
        "  scene_iterator = scene_dataset.make_initializable_iterator(); scene_handle = sess.run(scene_iterator.string_handle());\n",
        "  \n",
        "  return handle, next_element, pic_iterator, pic_handle, scene_iterator, scene_handle;\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEjnUazJyo1X"
      },
      "source": [
        "def conv_2d(inp_ten, kernel_sz = 4, strides = 1, out_channels = 64, is_conv = True, is_act = True, activation = \"relu\", \n",
        "            leak_param = 1/5.5, is_norm = True, normalization = \"instance\", use_bias = False, padding = \"SAME\"):\n",
        "\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    inp_ten:       Input Tensor\n",
        "    kernel_sz:     Integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window\n",
        "    strides:       Integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width\n",
        "    out_channels:  Integer, the dimensionality of the output space\n",
        "    is_conv:       Boolean, whether to perform convolution or not\n",
        "    is_norm:       Boolean, whether to normalize the data or not\n",
        "    normalization: Type of normalization, supports batch and instance normalization\n",
        "    is_act:        Boolean, whether to apply non-linear activation functions or not\n",
        "    activation:    Type of activation function, supports Leaky_ReLU, ReLU and Elu\n",
        "    leak_param:    Integer, Leakiness to use in case of Leaky ReLU\n",
        "    padding:       \"Valid\" (Reflection padding) or \"SAME\"(Constant padding filled with 0s)\n",
        "    use_bias:      Boolean, whether to use bias or not!\n",
        "    \n",
        "    Returns:\n",
        "    x:             Output Tensor\n",
        "    \"\"\"\n",
        "\n",
        "    if padding == \"VALID\":\n",
        "      inp_ten = tf.pad(inp_ten, [[0,0],[kernel_sz//2, kernel_sz//2],[kernel_sz//2, kernel_sz//2],[0,0]], 'REFLECT'); \n",
        "      \n",
        "    if is_conv:\n",
        "      x = tf.layers.conv2d(inputs = inp_ten, filters = out_channels, kernel_size = kernel_sz, strides = strides, padding = padding,\n",
        "          use_bias = use_bias, kernel_initializer = tf.random_normal_initializer(mean = 0, stddev = 0.02, dtype = tf.float32));\n",
        "      \n",
        "    if is_norm:\n",
        "      if normalization == \"batch\": x = tf.layers.batch_normalization(x, momentum = 0.9, epsilon = 1e-5, training = train_mode);\n",
        "      elif normalization == \"instance\": x = tf.contrib.layers.instance_norm(x, epsilon = 1e-5);\n",
        "\n",
        "    if is_act:\n",
        "      if activation == \"relu\": x = tf.nn.relu(x, name = \"relu\");\n",
        "      elif activation == \"leaky_relu\": x = tf.nn.leaky_relu(x, alpha = leak_param, name = \"leaky_relu\");\n",
        "      elif activation == \"elu\": x = tf.nn.elu(x, name = \"elu\");\n",
        "      elif activation == \"tanh\": x = tf.nn.tanh(x, name = \"tanh\");\n",
        "      else: print(\"Check your Activation function\")\n",
        "\n",
        "    return x\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWaDgSx2y02l"
      },
      "source": [
        "def conv_2d_transpose(inp_ten, kernel_sz = 3, strides = 2, out_channels = 64, is_deconv = True, is_act = True, activation = \"relu\",\n",
        "                      leak_param = 1/5.5, is_norm = True, normalization = \"instance\", is_dropout = False, use_bias = False):\n",
        "    \n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    inp_ten:       Input Tensor\n",
        "    kernel_sz:     Integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window\n",
        "    strides:       Integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width\n",
        "    out_channels:  Integer, the dimensionality of the output space\n",
        "    is_conv:       Boolean, whether to perform convolution or not\n",
        "    is_norm:       Boolean, whether to normalize the data or not\n",
        "    normalization: Type of normalization, supports batch and instance normalization\n",
        "    is_act:        Boolean, whether to apply non-linear activation functions or not\n",
        "    activation:    Type of activation function, supports Leaky_ReLU, ReLU and Elu\n",
        "    leak_param:    Integer, Leakiness to use in case of Leaky ReLU\n",
        "    padding:       \"Valid\" (Reflection padding) or \"SAME\"(Constant padding filled with 0s)\n",
        "    use_bias:      Boolean, whether to use bias or not\n",
        "    is_dropout:    Boolean, whether to use dropout or not\n",
        "    \n",
        "    Returns:\n",
        "    x:             Output Tensor\n",
        "    \"\"\"\n",
        "\n",
        "    if is_deconv:\n",
        "        x = tf.layers.conv2d_transpose(inputs = inp_ten, filters = out_channels, kernel_size = kernel_sz, strides = strides, padding = \"SAME\",\n",
        "                      use_bias = use_bias, kernel_initializer = tf.random_normal_initializer(mean = 0, stddev = 0.02, dtype = tf.float32));\n",
        "    \n",
        "    if is_norm:\n",
        "        if normalization == \"batch\": x = tf.layers.batch_normalization(x, momentum = 0.9, epsilon = 1e-6, training = train_mode);\n",
        "        elif normalization == \"instance\": x = tf.contrib.layers.instance_norm(x, epsilon = 1e-5);\n",
        "            \n",
        "    if is_act:\n",
        "        if activation == \"relu\": x = tf.nn.relu(x, name = \"relu\");\n",
        "        elif activation == \"leaky_relu\": x = tf.nn.leaky_relu(x, alpha = leak_param, name = \"leaky_relu\");\n",
        "        elif activation == \"elu\": x = tf.nn.elu(x, name = \"elu\");\n",
        "        elif activation == \"tanh\": x = tf.nn.tanh(x, name = \"tanh\");\n",
        "        else: print(\"Check your Activation function\")\n",
        "            \n",
        "    if is_dropout: x = tf.nn.dropout(x, keep_prob = (1 - dropout))\n",
        "            \n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOssqvFCzF7I"
      },
      "source": [
        "def res_blk(inp_ten, kernel_sz = 3, strides = 1, out_channels = 256, name = None):\n",
        "    \n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    inp_ten:       Input tensor\n",
        "    kernel_sz:     Integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window\n",
        "    strides:       Integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width\n",
        "    out_channels:  Number of output filters in convolutional layer\n",
        "    name:          Name to be used inside variable scope \n",
        "    \n",
        "    Returns:\n",
        "    output:       Output tensor\n",
        "    \"\"\"\n",
        "\n",
        "    with tf.variable_scope(name):\n",
        "        \n",
        "        x = conv_2d(inp_ten, kernel_sz = kernel_sz, strides = strides, out_channels = out_channels, padding = \"VALID\");\n",
        "        x = conv_2d(x, kernel_sz = kernel_sz, strides = strides, out_channels = out_channels, is_act = False, padding = \"VALID\")\n",
        "        \n",
        "        return x + inp_ten;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YphiyezWzM5P"
      },
      "source": [
        "def Generator(inp_ten, out_channels = 64, name = None, reuse = False):\n",
        "\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    inp_ten:       Input tensor\n",
        "    out_channels:  Number of output filters in convolutional layer\n",
        "    name:          Name to be used inside variable scope \n",
        "    reuse:         Boolean, whether to reuse the variables of the network or not\n",
        "    \n",
        "    Returns:\n",
        "    output:       Output tensor\n",
        "    \"\"\"\n",
        "    \n",
        "    with tf.variable_scope(name, reuse = reuse):\n",
        "        \n",
        "        with tf.variable_scope(\"Block_1\"):\n",
        "        \t# First layer with kernel size of 7, and reflection padding (to avoid checkerboard artifacts)\n",
        "            x = conv_2d(inp_ten, kernel_sz = 7, strides = 1, out_channels = out_channels*1, padding = \"VALID\");\n",
        "            # Downsample the original image \n",
        "            x = conv_2d(x, kernel_sz = 3, strides = 2, out_channels = out_channels*2, padding = \"VALID\"); \n",
        "            x = conv_2d(x, kernel_sz = 3, strides = 2, out_channels = out_channels*4, padding = \"VALID\"); \n",
        "\n",
        "        # Apply the resblocks on the downsampled image \n",
        "        with tf.variable_scope(\"Block_2\"):\n",
        "            for i in range(9): x = res_blk(x, 3, 1, out_channels*4, name = \"ResBlk_\" + str(i));\n",
        "\n",
        "        with tf.variable_scope(\"Block_3\"):\n",
        "        \t# Apply conv2d_transpose to upsample the image back to original dimensions\n",
        "            x = conv_2d_transpose(x, kernel_sz = 3, strides = 2, out_channels = out_channels*2);\n",
        "            x = conv_2d_transpose(x, kernel_sz = 3, strides = 2, out_channels = out_channels*1);\n",
        "            # Last layer with no normalization, kernel size of 7, and tanh activation function\n",
        "            x = conv_2d(x, kernel_sz = 7, strides = 1, out_channels = 3, activation = \"tanh\", is_norm = False, padding = \"VALID\");\n",
        "\n",
        "        return x;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3WqyZtizX7l"
      },
      "source": [
        "def Discriminator(inp_ten, out_channels = 64, use_sigmoid = False, name = None, reuse = False):\n",
        "\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    inp_ten:       Input tensor\n",
        "    out_channels:  Number of output filters in convolutional layer\n",
        "    name:          Name to be used inside variable scope \n",
        "    reuse:         Boolean, whether to reuse the variables of the network or not\n",
        "    use_sigmoid:   Boolean, whether to use sigmoid at the last layer\n",
        "    Returns:\n",
        "    output:       Output tensor\n",
        "    \"\"\"\n",
        "    \n",
        "    # Patch GAN with 70*70 receptive field\n",
        "    with tf.variable_scope(name, reuse = reuse):\n",
        "        \n",
        "        # Stride 2 convolution, and \"Same\" padding \n",
        "        with tf.variable_scope(\"Block_1\"):\n",
        "        \t# No normalization at the first layer\n",
        "            x = conv_2d(inp_ten, kernel_sz = 4, strides = 2, out_channels = out_channels, is_norm = False, activation = \"leaky_relu\")\n",
        "\n",
        "        with tf.variable_scope(\"Block_2\"):\n",
        "            for i in range(1, 4): x = conv_2d(x, kernel_sz = 4, strides = 2, out_channels = out_channels*min(2**i, 8),\n",
        "                                              activation = \"leaky_relu\");\n",
        "\n",
        "        # Stride 1 convolution, and \"Same\" padding \n",
        "        with tf.variable_scope(\"Block_3\"):\n",
        "            x = conv_2d(x, kernel_sz = 4, strides = 1, out_channels = 1, is_norm = False, is_act = False, use_bias = True)\n",
        "\n",
        "        # use sigmoid only if the loss function is Cross-entropy (here we are using LS-GAN loss)\n",
        "        if use_sigmoid == True:\n",
        "            x = tf.nn.sigmoid(x); print('Sigmoid activation in the discriminator')\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaWXNOuszjI9"
      },
      "source": [
        "def fake_image_pool(num_fakes, fake, fake_pool):\n",
        "    \n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    num_fakes: Number of fake images generated till now\n",
        "    fake_img:  Fake image generated by Generator\n",
        "    fake_pool: Array to store those fake images\n",
        "    Returns:\n",
        "    fake:      Fake Image to be used to update the weights of the discriminator \n",
        "    \"\"\"\n",
        "\n",
        "    if(num_fakes < pool_size): fake_pool[num_fakes] = fake; return fake\n",
        "    else:\n",
        "      p = random.random();\n",
        "      if p > 0.5: \n",
        "        random_id = random.randint(0, pool_size-1); temp = fake_pool[random_id];\n",
        "        fake_pool[random_id] = fake; return temp;\n",
        "      else: return fake"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-nTGiqFzq6o"
      },
      "source": [
        "def get_loss(real_prob, fake_prob, fake_pool_prob):\n",
        "    \n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    real_prob:      Probability of the real image\n",
        "    fake_prob:      Probability of the fake image\n",
        "    fake_pool_prob: Probability of the image selected randomly from the pool\n",
        "    \n",
        "    Returns:\n",
        "    g_loss:         Generator loss\n",
        "    d_loss:         Discriminator loss\n",
        "    \"\"\"\n",
        "\n",
        "    # LS-GAN loss\n",
        "    with tf.variable_scope(\"Loss\"):\n",
        "      \n",
        "        g_loss =  tf.reduce_mean(tf.squared_difference(fake_prob, 1));\n",
        "        d_loss =  tf.reduce_mean(tf.squared_difference(real_prob, 1)); \n",
        "        d_loss += tf.reduce_mean(tf.square(fake_pool_prob)); d_loss *= 0.5;\n",
        "        \n",
        "        return g_loss, d_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MjXgkUAz0az"
      },
      "source": [
        "def get_optimizer(loss, var_list):\n",
        "\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    loss:          Loss to be minimized\n",
        "    var_list:      List of the variables to be optimized\n",
        "    Returns:\n",
        "    learning_step: Train_op of the network\n",
        "    \"\"\"\n",
        "\t\n",
        "    global_step = tf.Variable(0, trainable = False); starter_learning_rate = 2e-4; end_learning_rate = 0.0;\n",
        "    start_decay_step = 100000; decay_steps = 100000; beta1 = 0.5;\n",
        "\n",
        "    # Constant learning rate till 100 epochs, after that linearly decrease it to 0\n",
        "    learning_rate = (tf.where(tf.greater_equal(global_step, start_decay_step), tf.train.polynomial_decay(starter_learning_rate, \n",
        "        global_step - start_decay_step, decay_steps, end_learning_rate, power = 1.0), starter_learning_rate));\n",
        "\n",
        "      # Define the Adam optimizer with the non-default beta1\n",
        "    learning_step = tf.train.AdamOptimizer(learning_rate, beta1 = beta1).minimize(loss, global_step = global_step, \n",
        "                            var_list = var_list);\n",
        "    \n",
        "    return learning_step;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptL8LjVXz-TQ"
      },
      "source": [
        "def initialize_model(lambda_1 = 10, lambda_2 = 0.5):\n",
        "\n",
        "\t\"\"\"\n",
        "    Arguments:\n",
        "    lambda_1: Coef of the Cycle Loss \n",
        "    lambda_2: Coef of the Identity loss\n",
        "    \"\"\"\n",
        "    \n",
        "\tglobal input_a, input_b, fake_pool_a, fake_pool_b, train_mode, dropout, lr;\n",
        "\n",
        "\t# Define the placeholders\n",
        "\twith tf.name_scope(\"Place_holders\"):\n",
        "\t\tinput_a = tf.placeholder(dtype = tf.float32, shape = [None, img_height, img_width, img_channels], name = \"Img_A\");\n",
        "\t\tinput_b = tf.placeholder(dtype = tf.float32, shape = [None, img_height, img_width, img_channels], name = \"Img_B\");\n",
        "\t\tfake_pool_a = tf.placeholder(tf.float32, shape = [None, img_height, img_width, img_channels], name = \"Fake_pool_A\");\n",
        "\t\tfake_pool_b = tf.placeholder(tf.float32, shape = [None, img_height, img_width, img_channels], name = \"Fake_pool_B\");\n",
        "\t\tdropout = tf.placeholder(dtype = tf.float32, name = \"Dropout\"); train_mode = tf.placeholder(dtype = tf.bool);\n",
        "\n",
        "\tfake_b  = Generator(inp_ten = input_a, name = \"Generator_a2b\", reuse = False);\n",
        "\trecon_a = Generator(inp_ten = fake_b,  name = \"Generator_b2a\", reuse = False);\n",
        "\tfake_a  = Generator(inp_ten = input_b, name = \"Generator_b2a\", reuse = True);\n",
        "\trecon_b = Generator(inp_ten = fake_a,  name = \"Generator_a2b\", reuse = True);\n",
        "\n",
        "\t# Fake Image generated by both the Generators for the Identity loss\n",
        "\tfake_b_ = Generator(inp_ten = input_b, name = \"Generator_a2b\", reuse = True);\n",
        "\tfake_a_ = Generator(inp_ten = input_a, name = \"Generator_b2a\", reuse = True);\n",
        "\n",
        "\treal_prob_a = Discriminator(inp_ten = input_a, name = \"Discriminator_a\", reuse = False);\n",
        "\tfake_prob_a = Discriminator(inp_ten = fake_a,  name = \"Discriminator_a\", reuse = True);\n",
        "\treal_prob_b = Discriminator(inp_ten = input_b, name = \"Discriminator_b\", reuse = False);\n",
        "\tfake_prob_b = Discriminator(inp_ten = fake_b,  name = \"Discriminator_b\", reuse = True);\n",
        "\n",
        "\t# Probabilities  outputted by the Discriminator corresponding to the fake image pool\n",
        "\tfake_prob_pool_a = Discriminator(fake_pool_a,  name = \"Discriminator_a\", reuse = True);\n",
        "\tfake_prob_pool_b = Discriminator(fake_pool_b,  name = \"Discriminator_b\", reuse = True); \n",
        "\n",
        "\tupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "\twith tf.control_dependencies(update_ops):\n",
        "\n",
        "\t\t# Get the Loss\n",
        "\t\tg_b2a_loss, d_a_loss = get_loss(real_prob_a, fake_prob_a, fake_prob_pool_a); \n",
        "\t\tg_a2b_loss, d_b_loss = get_loss(real_prob_b, fake_prob_b, fake_prob_pool_b);\n",
        "\n",
        "\t\t# Cycle Consistency and Identity Loss\n",
        "\t\tcycle_consistency_loss = lambda_1*(tf.reduce_mean(tf.abs(input_a - recon_a)) + tf.reduce_mean(tf.abs(input_b - recon_b)));\n",
        "\t\tidentity_loss = lambda_1*lambda_2*(tf.reduce_mean(tf.abs(input_a - fake_a_)) + tf.reduce_mean(tf.abs(input_b - fake_b_)));\n",
        "\n",
        "\t\t# Net Loss of both the generators\n",
        "\t\tg_b2a_loss = g_b2a_loss + cycle_consistency_loss + identity_loss; \n",
        "\t\tg_a2b_loss = g_a2b_loss + cycle_consistency_loss + identity_loss;\n",
        "\n",
        "\t\t# Seperate out the variables of each network\n",
        "\t\td_a_vars = [var for var in tf.trainable_variables() if \"Discriminator_a\" in var.name]\n",
        "\t\td_b_vars = [var for var in tf.trainable_variables() if \"Discriminator_b\" in var.name]\n",
        "\t\tg_b2a_vars = [var for var in tf.trainable_variables() if \"Generator_b2a\" in var.name]\n",
        "\t\tg_a2b_vars = [var for var in tf.trainable_variables() if \"Generator_a2b\" in var.name]\n",
        "\n",
        "\t\t# Define the train_ops\n",
        "\t\td_a_train_op   = get_optimizer(d_a_loss, var_list = d_a_vars); g_b2a_train_op = get_optimizer(g_b2a_loss, var_list = g_b2a_vars)\n",
        "\t\td_b_train_op   = get_optimizer(d_b_loss, var_list = d_b_vars); g_a2b_train_op = get_optimizer(g_a2b_loss, var_list = g_a2b_vars)\n",
        "\n",
        "\t\treturn fake_b, recon_a, fake_a, recon_b, d_a_loss, d_a_train_op, d_b_loss, d_b_train_op, g_b2a_loss, g_b2a_train_op, g_a2b_loss, g_a2b_train_op;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYsRjS7N0Le8"
      },
      "source": [
        "def show_images(image_batch, tmp_path = None, show = False, save = True, id = None, **kwargs):\n",
        "\n",
        "\t# Helper function to show some nice plots\n",
        "\n",
        "\timage_batch = (image_batch + 1)*0.5; img_index = 1; fig = plt.figure(figsize = (14, 8), **kwargs); \n",
        "\tfor _ in range(2):\n",
        "\t\tfor _ in range(3):\n",
        "\t\t\tfig.add_subplot(2, 3, img_index); plt.imshow(image_batch[img_index - 1], cmap = 'binary'); \n",
        "\t\t\tplt.gca().set_xticks([]); plt.gca().set_yticks([]); img_index += 1;\n",
        "\t\t\t\n",
        "\tif not os.path.exists(tmp_path): os.makedirs(tmp_path);\n",
        "\tplt.savefig(os.path.join(tmp_path, '{}.png'.format(id))); plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4VHfO3JL3Jo"
      },
      "source": [
        "def train(num_epochs, num_iters):\n",
        "  \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
        "\n",
        "\tg_train = tf.get_default_graph();\n",
        "\twith g_train.as_default():\n",
        "\t\ttf.set_random_seed(0); num_fake_imgs = 0;\n",
        "\t\twith tf.Session(graph = g_train) as sess:\n",
        "\n",
        "\t\t\tfake_b, recon_a, fake_a, recon_b, d_a_loss, d_a_train_op, d_b_loss, d_b_train_op, g_b2a_loss, g_b2a_train_op, \\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tg_a2b_loss, g_a2b_train_op = initialize_model();\n",
        "\t\t\t'''\n",
        "\t\t\timported_graph = tf.train.import_meta_graph('gdrive/My Drive/Saved Model/saved_variable.meta')\n",
        "\t\t\t# restore the saved vairable\n",
        "\t\t\timported_graph.restore(sess, 'gdrive/My Drive/Saved Model/saved_variable')\n",
        "\t\t\t# print the loaded variable\n",
        "\t\t\tfake_b, recon_a, fake_a, recon_b, d_a_loss, d_a_train_op, d_b_loss, d_b_train_op, g_b2a_loss, g_b2a_train_op, \\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tg_a2b_loss, g_a2b_train_op= sess.run(['Variable:0','beta1_power:0', 'beta2_power:0', 'Variable_1:0','beta1_power_1:0', 'beta2_power_1:0', \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'Variable_2:0','beta1_power_2:0', 'beta2_power_2:0', 'Variable_3:0','beta1_power_3:0', 'beta2_power_3:0'])\n",
        "\t\t\t'''\n",
        "    \n",
        "\t\t\n",
        "\t\t\thandle, next_element, pic_iterator, pic_handle, scene_iterator, scene_handle = get_iterators(sess);\n",
        "\t\t\tsess.run(tf.global_variables_initializer()); sess.run(pic_iterator.initializer); sess.run(scene_iterator.initializer); \n",
        "\t\t\tprint(\"Training Started...\"); tot_D_A_Loss = tot_G_A_loss = tot_D_B_Loss = tot_G_B_Loss = 0;\n",
        "\n",
        "\t\t\tfor iters in range(1, num_epochs*num_iters):\n",
        "\n",
        "\t\t\t\ttry: img_a = sess.run(next_element, feed_dict = {handle: pic_handle});\n",
        "\t\t\t\texcept tf.errors.OutOfRangeError: sess.run(pic_iterator.initializer);\n",
        "\n",
        "\t\t\t\ttry: img_b = sess.run(next_element, feed_dict = {handle: scene_handle})\n",
        "\t\t\t\texcept tf.errors.OutOfRangeError: sess.run(scene_iterator.initializer); \n",
        "\n",
        "\t\t\t\tif img_a.shape[-1] != 3 or img_b.shape[-1] != 3: continue;\n",
        "\n",
        "\t\t\t\t# Update Generator and Discriminator alternately (Start with the Generator) \n",
        "\t\t\t\t_, Fake_A, G_A_loss = sess.run([g_b2a_train_op, fake_a, g_b2a_loss], feed_dict = {input_a: img_a, \n",
        "\t\t\t\t\t\t\t\tinput_b: img_b, train_mode: True, dropout: 0})\n",
        "\t\t\t\t\n",
        "\t\t\t\tFake_pool_A = fake_image_pool(num_fake_imgs, Fake_A, fake_a_arr);\n",
        "\t\t\t\t_, D_A_Loss = sess.run([d_a_train_op, d_a_loss], feed_dict = {input_a: img_a, input_b: img_b, \n",
        "\t\t\t\t\t\t\tfake_pool_a: Fake_pool_A, train_mode: True, dropout: 0})\n",
        "\t\t\t\t\n",
        "\t\t\t\t_, Fake_B, G_B_Loss = sess.run([g_a2b_train_op, fake_b, g_a2b_loss], feed_dict = {input_a: img_a, \n",
        "\t\t\t\t\t\t\t\tinput_b: img_b, train_mode: True, dropout: 0})\n",
        "\t\t\t\t\n",
        "\t\t\t\tFake_pool_B = fake_image_pool(num_fake_imgs, Fake_B, fake_b_arr);\n",
        "\t\t\t\t_, D_B_Loss = sess.run([d_b_train_op, d_b_loss], feed_dict = {input_a: img_a, input_b: img_b, \n",
        "\t\t\t\t\t\t\tfake_pool_b: Fake_pool_B, train_mode: True, dropout: 0})\n",
        "\n",
        "\t\t\t\t# Gather some Statistics\n",
        "\t\t\t\ttot_D_A_Loss += D_A_Loss; tot_G_A_loss += G_A_loss; \n",
        "\t\t\t\ttot_D_B_Loss += D_B_Loss; tot_G_B_Loss += G_B_Loss;\n",
        "\t\t\t\tnum_fake_imgs += 1;\n",
        "\n",
        "\t\t\t\tif iters%num_iters == 0:\n",
        "\n",
        "\t\t\t\t\tFake_img_B  = sess.run(fake_b, feed_dict = {input_a: img_a, train_mode: True, dropout: 0});\n",
        "\t\t\t\t\tFake_img_A  = sess.run(fake_a, feed_dict = {input_b: img_b, train_mode: True, dropout: 0});\n",
        "\n",
        "\t\t\t\t\tRecon_img_B = sess.run(recon_b, feed_dict = {input_b: img_b, train_mode: True, dropout: 0});\n",
        "\t\t\t\t\tRecon_img_A = sess.run(recon_a, feed_dict = {input_a: img_a, train_mode: True, dropout: 0});\n",
        "\n",
        "\t\t\t\t\timage_batch = np.concatenate((img_a, Fake_img_B, Recon_img_A, img_b, Fake_img_A, Recon_img_B)); \n",
        "\t\t\t\t\tshow_images(image_batch, tmp_path = \"gdrive/My Drive/CycleGANtrials/\", id = iters);\n",
        "\n",
        "\t\t\t\t\tprint('After ' + str(iters)+ ': D_A_Loss: ' + str(tot_D_A_Loss/iters) + ', D_B_Loss: ' + \\\n",
        "\t\t\t\t\t      str(tot_D_B_Loss/iters) + ', G_B2A_loss: ' + str(tot_G_A_loss/iters) + ', G_A2B_Loss: ' + \\\n",
        "\t\t\t\t\t      str(tot_G_B_Loss/iters));\n",
        "\n",
        "\t\t\tsaver = tf.train.Saver();\n",
        "\t\t\tfor i, var in enumerate(saver._var_list):\n",
        "\t\t\t\t\tprint('Var {}: {}'.format(i, var));\n",
        "\t\t\tsaved_path = saver.save(sess, 'gdrive/My Drive/Saved Model/saved_variable');\n",
        "\t\t\tprint('model saved in {}'.format(saved_path));\n",
        " \n",
        "\t\t\t\t\t\n",
        "\ttf.reset_default_graph(); return;\n",
        "\n",
        "tf.get_default_graph(); train(3, min(len(pic_file_name), len(scene_file_name)));\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AInBYgd7gIgH"
      },
      "source": [
        "def train(num_epochs, num_iters):\n",
        "\tg_train = tf.get_default_graph();\n",
        "\twith g_train.as_default():\n",
        "\t\tloaded_model = False\n",
        "\t\ttry:\n",
        "\t\t\tsaver = tf.train.import_meta_graph('gdrive/My Drive/Saved Model/saved_variable.meta')\n",
        "\t\t\tloaded_model = True\n",
        "\t\texcept:  \n",
        "\t\t\tpass\n",
        "\t\ttf.set_random_seed(0); num_fake_imgs = 0;\n",
        "\t\twith tf.Session(graph = g_train) as sess:\n",
        "\n",
        "\t\t\tif loaded_model:\n",
        "\t\t\t\tsaver.restore(sess, 'gdrive/My Drive/Saved Model/saved_variable')\n",
        "\t\t\n",
        "\t\t\telse:\n",
        "\t\t\t\tfake_b, recon_a, fake_a, recon_b, d_a_loss, d_a_train_op, d_b_loss, d_b_train_op, g_b2a_loss, g_b2a_train_op, \\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tg_a2b_loss, g_a2b_train_op = initialize_model();\n",
        "\t\t\t'''\n",
        "\t\t\timported_graph = tf.train.import_meta_graph('gdrive/My Drive/Saved Model/saved_variable.meta')\n",
        "\t\t\t# restore the saved vairable\n",
        "\t\t\timported_graph.restore(sess, 'gdrive/My Drive/Saved Model/saved_variable')\n",
        "\t\t\t# print the loaded variable\n",
        "\t\t\tfake_b, recon_a, fake_a, recon_b, d_a_loss, d_a_train_op, d_b_loss, d_b_train_op, g_b2a_loss, g_b2a_train_op, \\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tg_a2b_loss, g_a2b_train_op= sess.run(['Variable:0','beta1_power:0', 'beta2_power:0', 'Variable_1:0','beta1_power_1:0', 'beta2_power_1:0', \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'Variable_2:0','beta1_power_2:0', 'beta2_power_2:0', 'Variable_3:0','beta1_power_3:0', 'beta2_power_3:0'])\n",
        "\t\t\t'''\n",
        "    \n",
        "\t\t\n",
        "\t\t\thandle, next_element, pic_iterator, pic_handle, scene_iterator, scene_handle = get_iterators(sess);\n",
        "\t\t\tsess.run(tf.global_variables_initializer()); sess.run(pic_iterator.initializer); sess.run(scene_iterator.initializer); \n",
        "\t\t\tprint(\"Training Started...\"); tot_D_A_Loss = tot_G_A_loss = tot_D_B_Loss = tot_G_B_Loss = 0;\n",
        "\n",
        "\t\t\tfor iters in range(1, num_epochs*num_iters):\n",
        "\n",
        "\t\t\t\ttry: img_a = sess.run(next_element, feed_dict = {handle: pic_handle});\n",
        "\t\t\t\texcept tf.errors.OutOfRangeError: sess.run(pic_iterator.initializer);\n",
        "\n",
        "\t\t\t\ttry: img_b = sess.run(next_element, feed_dict = {handle: scene_handle})\n",
        "\t\t\t\texcept tf.errors.OutOfRangeError: sess.run(scene_iterator.initializer); \n",
        "\n",
        "\t\t\t\tif img_a.shape[-1] != 3 or img_b.shape[-1] != 3: continue;\n",
        "\n",
        "\t\t\t\t# Update Generator and Discriminator alternately (Start with the Generator) \n",
        "\t\t\t\t_, Fake_A, G_A_loss = sess.run([g_b2a_train_op, fake_a, g_b2a_loss], feed_dict = {input_a: img_a, \n",
        "\t\t\t\t\t\t\t\tinput_b: img_b, train_mode: True, dropout: 0})\n",
        "\t\t\t\t\n",
        "\t\t\t\tFake_pool_A = fake_image_pool(num_fake_imgs, Fake_A, fake_a_arr);\n",
        "\t\t\t\t_, D_A_Loss = sess.run([d_a_train_op, d_a_loss], feed_dict = {input_a: img_a, input_b: img_b, \n",
        "\t\t\t\t\t\t\tfake_pool_a: Fake_pool_A, train_mode: True, dropout: 0})\n",
        "\t\t\t\t\n",
        "\t\t\t\t_, Fake_B, G_B_Loss = sess.run([g_a2b_train_op, fake_b, g_a2b_loss], feed_dict = {input_a: img_a, \n",
        "\t\t\t\t\t\t\t\tinput_b: img_b, train_mode: True, dropout: 0})\n",
        "\t\t\t\t\n",
        "\t\t\t\tFake_pool_B = fake_image_pool(num_fake_imgs, Fake_B, fake_b_arr);\n",
        "\t\t\t\t_, D_B_Loss = sess.run([d_b_train_op, d_b_loss], feed_dict = {input_a: img_a, input_b: img_b, \n",
        "\t\t\t\t\t\t\tfake_pool_b: Fake_pool_B, train_mode: True, dropout: 0})\n",
        "\n",
        "\t\t\t\t# Gather some Statistics\n",
        "\t\t\t\ttot_D_A_Loss += D_A_Loss; tot_G_A_loss += G_A_loss; \n",
        "\t\t\t\ttot_D_B_Loss += D_B_Loss; tot_G_B_Loss += G_B_Loss;\n",
        "\t\t\t\tnum_fake_imgs += 1;\n",
        "\n",
        "\t\t\t\tif iters%num_iters == 0:\n",
        "\n",
        "\t\t\t\t\tFake_img_B  = sess.run(fake_b, feed_dict = {input_a: img_a, train_mode: True, dropout: 0});\n",
        "\t\t\t\t\tFake_img_A  = sess.run(fake_a, feed_dict = {input_b: img_b, train_mode: True, dropout: 0});\n",
        "\n",
        "\t\t\t\t\tRecon_img_B = sess.run(recon_b, feed_dict = {input_b: img_b, train_mode: True, dropout: 0});\n",
        "\t\t\t\t\tRecon_img_A = sess.run(recon_a, feed_dict = {input_a: img_a, train_mode: True, dropout: 0});\n",
        "\n",
        "\t\t\t\t\timage_batch = np.concatenate((img_a, Fake_img_B, Recon_img_A, img_b, Fake_img_A, Recon_img_B)); \n",
        "\t\t\t\t\tshow_images(image_batch, tmp_path = \"gdrive/My Drive/CycleGANtrials/\", id = iters);\n",
        "\n",
        "\t\t\t\t\tprint('After ' + str(iters)+ ': D_A_Loss: ' + str(tot_D_A_Loss/iters) + ', D_B_Loss: ' + \\\n",
        "\t\t\t\t\t      str(tot_D_B_Loss/iters) + ', G_B2A_loss: ' + str(tot_G_A_loss/iters) + ', G_A2B_Loss: ' + \\\n",
        "\t\t\t\t\t      str(tot_G_B_Loss/iters));\n",
        "\n",
        "\t\t\tsaver = tf.train.Saver();\n",
        "\t\t\tfor i, var in enumerate(saver._var_list):\n",
        "\t\t\t\t\tprint('Var {}: {}'.format(i, var));\n",
        "\t\t\tsaved_path = saver.save(sess, 'gdrive/My Drive/Saved Model/saved_variable');\n",
        "\t\t\tprint('model saved in {}'.format(saved_path));\n",
        " \n",
        "\t\t\t\t\t\n",
        "\ttf.reset_default_graph(); return;\n",
        "\n",
        "tf.get_default_graph(); train(3, min(len(pic_file_name), len(scene_file_name)));\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zJfcR6XNgIx"
      },
      "source": [
        "def train2(num_epochs, num_iters):\n",
        "\tg_train = tf.get_default_graph();\n",
        "\twith g_train.as_default():\n",
        "\t\ttf.set_random_seed(0); num_fake_imgs = 0;\n",
        "\t\twith tf.Session(graph = g_train) as sess:\n",
        "\n",
        "\t\t\tfake_b, recon_a, fake_a, recon_b, d_a_loss, d_a_train_op, d_b_loss, d_b_train_op, g_b2a_loss, g_b2a_train_op, \\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tg_a2b_loss, g_a2b_train_op = initialize_model();\n",
        "\t\t\t'''\n",
        "\t\t\t# print the loaded variable\n",
        "\t\t\tfake_b, recon_a, fake_a, recon_b, d_a_loss, d_a_train_op, d_b_loss, d_b_train_op, g_b2a_loss, g_b2a_train_op, \\\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tg_a2b_loss, g_a2b_train_op= sess.run(['Variable:0','beta1_power:0', 'beta2_power:0', 'Variable_1:0','beta1_power_1:0', 'beta2_power_1:0', \n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'Variable_2:0','beta1_power_2:0', 'beta2_power_2:0', 'Variable_3:0','beta1_power_3:0', 'beta2_power_3:0'])\n",
        "\t\t\t'''\n",
        "    \n",
        "\t\t\n",
        "\t\t\thandle, next_element, pic_iterator, pic_handle, scene_iterator, scene_handle = get_iterators(sess);\n",
        "\t\t\tsess.run(tf.global_variables_initializer()); sess.run(pic_iterator.initializer); sess.run(scene_iterator.initializer); \n",
        "\n",
        "      try:\n",
        "        \tsaver = tf.train.import_meta_graph('gdrive/My Drive/Saved Model/saved_variable.meta')\n",
        "          # restore the saved vairable\n",
        "          saver.restore(sess, 'gdrive/My Drive/Saved Model/saved_variable')\n",
        "      except:\n",
        "          print(\"Did not load variables, using fresh values.\")\n",
        "\n",
        "\n",
        "\t\t\tprint(\"Training Started...\"); tot_D_A_Loss = tot_G_A_loss = tot_D_B_Loss = tot_G_B_Loss = 0;\n",
        "\n",
        "\t\t\tfor iters in range(1, num_epochs*num_iters):\n",
        "\n",
        "\t\t\t\ttry: img_a = sess.run(next_element, feed_dict = {handle: pic_handle});\n",
        "\t\t\t\texcept tf.errors.OutOfRangeError: sess.run(pic_iterator.initializer);\n",
        "\n",
        "\t\t\t\ttry: img_b = sess.run(next_element, feed_dict = {handle: scene_handle})\n",
        "\t\t\t\texcept tf.errors.OutOfRangeError: sess.run(scene_iterator.initializer); \n",
        "\n",
        "\t\t\t\tif img_a.shape[-1] != 3 or img_b.shape[-1] != 3: continue;\n",
        "\n",
        "\t\t\t\t# Update Generator and Discriminator alternately (Start with the Generator) \n",
        "\t\t\t\t_, Fake_A, G_A_loss = sess.run([g_b2a_train_op, fake_a, g_b2a_loss], feed_dict = {input_a: img_a, \n",
        "\t\t\t\t\t\t\t\tinput_b: img_b, train_mode: True, dropout: 0})\n",
        "\t\t\t\t\n",
        "\t\t\t\tFake_pool_A = fake_image_pool(num_fake_imgs, Fake_A, fake_a_arr);\n",
        "\t\t\t\t_, D_A_Loss = sess.run([d_a_train_op, d_a_loss], feed_dict = {input_a: img_a, input_b: img_b, \n",
        "\t\t\t\t\t\t\tfake_pool_a: Fake_pool_A, train_mode: True, dropout: 0})\n",
        "\t\t\t\t\n",
        "\t\t\t\t_, Fake_B, G_B_Loss = sess.run([g_a2b_train_op, fake_b, g_a2b_loss], feed_dict = {input_a: img_a, \n",
        "\t\t\t\t\t\t\t\tinput_b: img_b, train_mode: True, dropout: 0})\n",
        "\t\t\t\t\n",
        "\t\t\t\tFake_pool_B = fake_image_pool(num_fake_imgs, Fake_B, fake_b_arr);\n",
        "\t\t\t\t_, D_B_Loss = sess.run([d_b_train_op, d_b_loss], feed_dict = {input_a: img_a, input_b: img_b, \n",
        "\t\t\t\t\t\t\tfake_pool_b: Fake_pool_B, train_mode: True, dropout: 0})\n",
        "\n",
        "\t\t\t\t# Gather some Statistics\n",
        "\t\t\t\ttot_D_A_Loss += D_A_Loss; tot_G_A_loss += G_A_loss; \n",
        "\t\t\t\ttot_D_B_Loss += D_B_Loss; tot_G_B_Loss += G_B_Loss;\n",
        "\t\t\t\tnum_fake_imgs += 1;\n",
        "\n",
        "\t\t\t\tif iters%num_iters == 0:\n",
        "\n",
        "\t\t\t\t\tFake_img_B  = sess.run(fake_b, feed_dict = {input_a: img_a, train_mode: True, dropout: 0});\n",
        "\t\t\t\t\tFake_img_A  = sess.run(fake_a, feed_dict = {input_b: img_b, train_mode: True, dropout: 0});\n",
        "\n",
        "\t\t\t\t\tRecon_img_B = sess.run(recon_b, feed_dict = {input_b: img_b, train_mode: True, dropout: 0});\n",
        "\t\t\t\t\tRecon_img_A = sess.run(recon_a, feed_dict = {input_a: img_a, train_mode: True, dropout: 0});\n",
        "\n",
        "\t\t\t\t\timage_batch = np.concatenate((img_a, Fake_img_B, Recon_img_A, img_b, Fake_img_A, Recon_img_B)); \n",
        "\t\t\t\t\tshow_images(image_batch, tmp_path = \"gdrive/My Drive/CycleGANtrials/\", id = iters);\n",
        "\n",
        "\t\t\t\t\tprint('After ' + str(iters)+ ': D_A_Loss: ' + str(tot_D_A_Loss/iters) + ', D_B_Loss: ' + \\\n",
        "\t\t\t\t\t      str(tot_D_B_Loss/iters) + ', G_B2A_loss: ' + str(tot_G_A_loss/iters) + ', G_A2B_Loss: ' + \\\n",
        "\t\t\t\t\t      str(tot_G_B_Loss/iters));\n",
        "\n",
        "\t\t\tsaver = tf.train.Saver();\n",
        "\t\t\t#for i, var in enumerate(saver._var_list):\n",
        "\t\t\t\t\t#print('Var {}: {}'.format(i, var));\n",
        "\t\t\tsaved_path = saver.save(sess, 'gdrive/My Drive/Saved Model/saved_variable');\n",
        "\t\t\tprint('model saved in {}'.format(saved_path));\n",
        " \n",
        "\t\t\t\t\t\n",
        "\ttf.reset_default_graph(); return;\n",
        "\n",
        "tf.get_default_graph(); train2(3, min(len(pic_file_name), len(scene_file_name)));\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}